{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "import os\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset\n",
    "import cv2\n",
    "import torch.nn.functional as F\n",
    "import torchvision.models as models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def gen_edge_mask(mask):\n",
    "#     # Convert mask to binary image\n",
    "#     mask = cv2.threshold(mask, 0.5, 1, cv2.THRESH_BINARY)[1]\n",
    "    \n",
    "#     # Compute edges using the Canny edge detection algorithm\n",
    "#     edges = cv2.Canny(np.uint8(mask * 255), 100, 200)\n",
    "    \n",
    "#     # Dilate edges to make them thicker\n",
    "#     kernel = np.ones((3, 3), np.uint8)\n",
    "#     edges = cv2.dilate(edges, kernel, iterations=1)\n",
    "    \n",
    "#     # Return the edge mask\n",
    "#     return edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose([\n",
    "                    transforms.ToTensor(), \n",
    "            ])\n",
    "\n",
    "trainset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "testset=datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=10,shuffle=True, num_workers=3)\n",
    "\n",
    "testloader = torch.utils.data.DataLoader(testset,batch_size=10,shuffle=True,num_workers=3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Bayar CNN or Constrained CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BayarConv2d(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size=5, stride=1, padding=0):\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.kernel_size = kernel_size\n",
    "        self.stride = stride\n",
    "        self.padding = padding\n",
    "        self.minus1 = (torch.ones(self.in_channels, self.out_channels, 1) * -1.000)\n",
    "\n",
    "        super(BayarConv2d, self).__init__()\n",
    "        # only (kernel_size ** 2 - 1) trainable params as the center element is always -1\n",
    "        self.kernel = nn.Parameter(torch.rand(self.in_channels, self.out_channels, kernel_size ** 2 - 1),\n",
    "                                   requires_grad=True)\n",
    "\n",
    "\n",
    "    def bayarConstraint(self):\n",
    "        self.kernel.data = self.kernel.permute(2, 0, 1)\n",
    "        self.kernel.data = torch.div(self.kernel.data, self.kernel.data.sum(0))\n",
    "        self.kernel.data = self.kernel.permute(1, 2, 0)\n",
    "        ctr = self.kernel_size ** 2 // 2\n",
    "        real_kernel = torch.cat((self.kernel[:, :, :ctr], self.minus1.to(self.kernel.device), self.kernel[:, :, ctr:]), dim=2)\n",
    "        real_kernel = real_kernel.reshape((self.out_channels, self.in_channels, self.kernel_size, self.kernel_size))\n",
    "        return real_kernel\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.conv2d(x, self.bayarConstraint(), stride=self.stride, padding=self.padding)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BayarConv(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BayarConv, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=3, kernel_size=5, padding=2, bias=False)\n",
    "\n",
    "        weight = self.conv1.weight.data\n",
    "        sum_all_except_center = torch.sum(weight[:, :, :, :] - weight[:, :, 2:3, 2:3], dim=(1, 2, 3), keepdim=True)\n",
    "        # weight[:, :, :, :] -= weight[:, :, 2:3, 2:3]\n",
    "        weight[:, :, :, :] /= sum_all_except_center\n",
    "        weight[:, :, 2:3, 2:3] = -1.0\n",
    "\n",
    "        self.conv.weight.data[:, :, :, :] = weight\n",
    "\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = self.conv1(x)\n",
    "\n",
    "\n",
    "        with torch.no_grad():\n",
    "            weight = self.conv1.weight.data\n",
    "            sum_all_except_center = torch.sum(weight[:, :, :, :] - weight[:, :, 2:3, 2:3], dim=(1, 2, 3), keepdim=True)\n",
    "            weight[:, :, :, :] -= weight[:, :, 2:3, 2:3]\n",
    "            weight[:, :, :, :] /= sum_all_except_center\n",
    "            weight[:, :, 2:3, 2:3] = -1.0\n",
    "            self.conv.weight.data[:, :, :, :] = weight\n",
    "            \n",
    "        return x"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ERB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ERB(nn.Module):\n",
    "    def __init__(self,in_channels,strides):\n",
    "        super(ERB,self).__init__()\n",
    "\n",
    "        self.relu=nn.ReLU()\n",
    "        self.batch_norm=nn.BatchNorm2d(1)\n",
    "        self.cnn_1=nn.Conv2d(in_channels,1,kernel_size=1,stride=strides,padding=0)\n",
    "        self.cnn_2=nn.Conv2d(1,1,kernel_size=3,stride=strides,padding=1)\n",
    "\n",
    "    def forward(self,x):\n",
    "        temp=x\n",
    "        temp=self.cnn_1(temp)\n",
    "        x1=self.cnn_2(temp)\n",
    "        x1=self.batch_norm(x1)\n",
    "        x1=self.relu(x1)\n",
    "        x1=self.cnn_2(x1)\n",
    "\n",
    "        fin=temp+x1\n",
    "\n",
    "        return fin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 1, 4, 4])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "erb=ERB(512,1)\n",
    "erb(torch.randn(10, 512, 4, 4) ).shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Sobel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sobel_layer(nn.Module):\n",
    "    def __init__(self,in_channels,out_channels):\n",
    "        super(Sobel_layer, self).__init__()\n",
    "        self.conv_x = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=1, padding=1,bias=False)\n",
    "        self.batch_norm=nn.BatchNorm2d(out_channels)\n",
    "        self.sigmoid=nn.Sigmoid()\n",
    "        # self.normm=torch.norm()\n",
    "\n",
    "        for j in range(out_channels):\n",
    "            for i in range(in_channels):\n",
    "                self.conv_x.weight.data[j, i, :, :] = torch.Tensor([[-1, 0, 1], [-2, 0, 2], [-1, 0, 1]])\n",
    "        \n",
    "        # self.conv_x.weight.data[1, 0, :, :] = torch.Tensor([[-1, 0, 1], [-2, 0, 2], [-1, 0, 1]])\n",
    "        # self.conv_x.weight.data[1, 1, :, :] = torch.Tensor([[-1, 0, 1], [-2, 0, 2], [-1, 0, 1]])\n",
    "        # self.conv_x.weight.data[1, 2, :, :] = torch.Tensor([[-1, 0, 1], [-2, 0, 2], [-1, 0, 1]])\n",
    "\n",
    "        self.conv_y = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=1, padding=1,bias=False)\n",
    "\n",
    "        for j in range(out_channels):\n",
    "            for i in range(in_channels):\n",
    "                self.conv_y.weight.data[j, i, :, :] = torch.Tensor([[-1, -2, -1], [0, 0, 0], [1, 2, 1]])\n",
    "      \n",
    "        # self.conv_y.weight.data[1, 0, :, :] = torch.Tensor([[-1, -2, -1], [0, 0, 0], [1, 2, 1]])\n",
    "        # self.conv_y.weight.data[1, 1, :, :] = torch.Tensor([[-1, -2, -1], [0, 0, 0], [1, 2, 1]])\n",
    "        # self.conv_y.weight.data[1, 2, :, :] = torch.Tensor([[-1, -2, -1], [0, 0, 0], [1, 2, 1]])\n",
    "\n",
    "    def forward(self, x):\n",
    "        temp_x=self.conv_x(x)\n",
    "        temp_x=self.batch_norm(temp_x)\n",
    "        temp_y=self.conv_y(x)\n",
    "        temp_y=self.batch_norm(temp_y)\n",
    "\n",
    "        temp = torch.sqrt(torch.pow(temp_x, 2) + torch.pow(temp_y, 2))\n",
    "\n",
    "\n",
    "        temp=self.sigmoid(temp)\n",
    "\n",
    "        # print(temp)\n",
    "        # print(x.shape)\n",
    "        \n",
    "        fin=temp*x\n",
    "        return fin\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Positional Attention Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Position(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Position,self).__init__()\n",
    "        self.conv1=nn.Conv2d(4096,512,kernel_size=1,stride=1,padding=0)\n",
    "        self.conv2=nn.Conv2d(4096,4096,kernel_size=1,stride=1,padding=0)\n",
    "\n",
    "        self.sm=nn.Softmax()\n",
    "        self.alpha = nn.Parameter(torch.tensor(0.0), requires_grad=True)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        w,h,c=x.size()\n",
    "        temp_1=self.conv1(x)\n",
    "        temp_1 = temp_1.reshape(-1, c)\n",
    "        temp_2=torch.transpose(temp_1,0,1)\n",
    "        position_attention_map=temp_1*temp_2\n",
    "\n",
    "        position_attention_map=self.sm(position_attention_map)\n",
    "\n",
    "        temp_2=self.conv2(x)\n",
    "        temp_2 = temp_2.reshape(-1, c)\n",
    "        position_attention_map=torch.transpose(position_attention_map,0,1)\n",
    "        fin=temp_2*position_attention_map\n",
    "        fin=fin.view(w,h,c)   \n",
    "        return self.alpha*fin+x\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Channel Attention Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Channel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Channel,self).__init__()\n",
    "\n",
    "        self.sm=nn.Softmax()\n",
    "        self.beta = nn.Parameter(torch.tensor(0.0), requires_grad=True)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        w,h,c=x.size()\n",
    "        temp_1 = x.reshape(-1, c)\n",
    "        temp_2=torch.transpose(temp_1,0,1)\n",
    "        channel_attention_map=temp_1*temp_2\n",
    "\n",
    "        channel_attention_map=self.sm(channel_attention_map)\n",
    "\n",
    "        channel_attention_map=torch.transpose(channel_attention_map,0,1)\n",
    "\n",
    "        fin=temp_1*channel_attention_map\n",
    "        fin=fin.view(w,h,c)   \n",
    "        return self.beta*fin+x"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Dual Attention Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dual(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Dual,self).__init__()\n",
    "        self.position = Position()\n",
    "        self.channel = Channel() \n",
    "        self.conv=nn.Conv2d(4096,1,kernel_size=1)\n",
    "\n",
    "    def forward(self,x):\n",
    "        temp1=self.position(x)\n",
    "        temp2=self.channel(x)\n",
    "        temp_3=temp1+temp2\n",
    "        return self.conv(temp_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet50=models.resnet50(pretrained=True)\n",
    "input_resize=torch.nn.functional.interpolate(images,size=(224,224))\n",
    "print(input_resize.shape)\n",
    "conv_layer = nn.Sequential(*list(resnet50.children())[:-2])\n",
    "output_tensor = conv_layer(input_resize)\n",
    "mx=nn.MaxPool2d(7)\n",
    "output_tensor=mx(output_tensor)\n",
    "flatten=nn.Flatten()\n",
    "output_tensor=flatten(output_tensor)\n",
    "linar=nn.Linear(2048,8*8*256)\n",
    "output_tensor=linar(output_tensor)\n",
    "output_tensor = output_tensor.view(100, 256, 8, 8)\n",
    "print(output_tensor.shape)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataiter = iter(trainloader)\n",
    "images, labels = next(dataiter)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyResNet50(nn.Module):\n",
    "    def __init__(self,in_channels):\n",
    "        super(MyResNet50, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        self.layer1 = nn.Sequential(*list(models.resnet50().children())[4])\n",
    "        self.layer2 = nn.Sequential(*list(models.resnet50().children())[5])\n",
    "        self.layer3 = nn.Sequential(*list(models.resnet50().children())[6])\n",
    "        self.layer4 = nn.Sequential(*list(models.resnet50().children())[7])\n",
    "        # self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        # self.fc = nn.Linear(2048, 1000)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "        # x = self.avgpool(x)\n",
    "        # x = x.view(x.size(0), -1)\n",
    "        # x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "resnet50_2 = MyResNet50(256) \n",
    "\n",
    "input_tensor = torch.randn(10, 256, 8, 8) \n",
    "\n",
    "\n",
    "output_tensor_2 = resnet50_2(input_tensor) \n",
    "\n",
    "print(output_tensor_2.shape) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MVSS(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MVSS,self).__init__()\n",
    "        resnet50=models.resnet50(pretrained=True)\n",
    "        self.conv_layer = nn.Sequential(*list(resnet50.children())[:-2])\n",
    "        self.mx=nn.MaxPool2d(7)\n",
    "        self.flatten=nn.Flatten()\n",
    "        self.sobel_1=Sobel_layer(256,256)\n",
    "        self.sobel_2=Sobel_layer(512,512)\n",
    "        self.sobel_3=Sobel_layer(1024,1024)\n",
    "        self.sobel_4=Sobel_layer(2048,2048)\n",
    "\n",
    "        self.erb1=ERB(256,1)\n",
    "        self.erb2=ERB(512,1)\n",
    "        self.erb3=ERB(1024,1)\n",
    "        self.erb4=ERB(2048,1)\n",
    "        self.erb5=ERB(1,1)\n",
    "\n",
    "        self.scale1 = nn.Upsample(scale_factor=2, mode=\"nearest\")\n",
    "        self.scale2 = nn.Upsample(scale_factor=4, mode=\"nearest\")\n",
    "        self.sig=nn.Sigmoid()\n",
    "\n",
    "        self.bayar=BayarConv2d(3,3)\n",
    "\n",
    "    def forward(self,x):\n",
    "\n",
    "        b,c,h,w=x.size()\n",
    "        input_resize=torch.nn.functional.interpolate(x,size=(224,224))\n",
    "        output_1=self.conv_layer(input_resize)\n",
    "        output_1=self.mx(output_1)\n",
    "        output_1=self.flatten(output_1)\n",
    "        linear_1=nn.Linear(2048,h//4*w//4*256)\n",
    "        res_1=linear_1(output_1).view(10, 256, w//4, h//4)   \n",
    "        # print(res_1.shape,  \"Required 10, 256, 8, 8\")\n",
    "        sb_1=self.sobel_1(res_1)\n",
    "        erb_1=self.erb1(sb_1)\n",
    "\n",
    "\n",
    "        input_resize_2=torch.nn.functional.interpolate(res_1,size=(224,224))      \n",
    "        resnet_2=MyResNet50(256)\n",
    "        output_2=resnet_2(input_resize_2)\n",
    "        output_2=self.flatten(output_2)\n",
    "        linear_2=nn.Linear(2048,h//8*w//8*512)\n",
    "        res_2=linear_2(output_1).view(10, 512, w//8, h//8)     \n",
    "        # print(res_2.shape,  \"Required 10, 512, 4, 4\")\n",
    "        sb_2=self.sobel_2(res_2)\n",
    "        erb_2=self.erb2(sb_2)\n",
    "\n",
    "\n",
    "        input_resize_3=torch.nn.functional.interpolate(res_2,size=(224,224))\n",
    "        resnet_3=MyResNet50(512)\n",
    "        output_3=resnet_3(input_resize_3)\n",
    "        output_3=self.mx(output_3)\n",
    "        output_3=self.flatten(output_3)\n",
    "        linear_3=nn.Linear(2048,h//16*w//16*1024)\n",
    "        res_3=linear_3(output_3).view(10, 1024, w//16, h//16)       \n",
    "        # print(res_3.shape,  \"Required 10, 1024, 2, 2\")\n",
    "        sb_3=self.sobel_3(res_3)\n",
    "        erb_3=self.erb3(sb_3)\n",
    "\n",
    "\n",
    "        input_resize_4=torch.nn.functional.interpolate(res_3,size=(224,224))\n",
    "        resnet_4=MyResNet50(1024)\n",
    "        output_4=resnet_4(input_resize_4)\n",
    "        output_4=self.mx(output_4)\n",
    "        output_4=self.flatten(output_4)\n",
    "        linear_4=nn.Linear(2048,h//16*w//16*2048)\n",
    "        res_4=linear_4(output_4).view(10, 2048, w//16, h//16)          \n",
    "        # print(res_4.shape,  \"Required 10, 2048, 2, 2\")\n",
    "        sb_4=self.sobel_4(res_4)\n",
    "        erb_4=self.erb4(sb_4)\n",
    "\n",
    "\n",
    "        erb_out1=erb_1+self.scale1(erb_2)\n",
    "        erb_out_2=self.erb5(erb_out1)\n",
    "        erb_out_3=self.scale2(erb_3)+erb_out_2\n",
    "        erb_out_4=self.erb5(erb_out_3)\n",
    "        erb_out_5=self.scale2(erb_4)+erb_out_4\n",
    "        final_erb_out=self.erb5(erb_out_5)\n",
    "\n",
    "        edge_out=self.sig(final_erb_out)\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "        return edge_out,res_4\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 1, 8, 8])\n"
     ]
    }
   ],
   "source": [
    "mvss=MVSS()\n",
    "mvss(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MVSS(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MVSS,self).__init__()\n",
    "        resnet50=models.resnet50(pretrained=True)\n",
    "        self.conv_layer = nn.Sequential(*list(resnet50.children())[:-2])\n",
    "        self.mx=nn.MaxPool2d(7)\n",
    "\n",
    "        self.gmp=nn.MaxPool2d(512)\n",
    "\n",
    "        self.flatten=nn.Flatten()\n",
    "        self.sobel_1=Sobel_layer(256,256)\n",
    "        self.sobel_2=Sobel_layer(512,512)\n",
    "        self.sobel_3=Sobel_layer(1024,1024)\n",
    "        self.sobel_4=Sobel_layer(2048,2048)\n",
    "\n",
    "        self.erb1=ERB(256,1)\n",
    "        self.erb2=ERB(512,1)\n",
    "        self.erb3=ERB(1024,1)\n",
    "        self.erb4=ERB(2048,1)\n",
    "        self.erb5=ERB(1,1)\n",
    "\n",
    "        self.scale1 = nn.Upsample(scale_factor=2, mode=\"nearest\")\n",
    "        self.scale2 = nn.Upsample(scale_factor=4, mode=\"nearest\")\n",
    "        self.sig=nn.Sigmoid()\n",
    "\n",
    "        self.bayar=BayarConv2d(3,3)\n",
    "        self.dual=Dual()\n",
    "\n",
    "\n",
    "\n",
    "    def forward(self,x):\n",
    "\n",
    "        b,c,h,w=x.size()\n",
    "        input_resize=torch.nn.functional.interpolate(x,size=(224,224))\n",
    "        output_1=self.conv_layer(input_resize)\n",
    "        output_1=self.mx(output_1)\n",
    "        output_1=self.flatten(output_1)\n",
    "        linear_1=nn.Linear(2048,h//4*w//4*256)\n",
    "        res_1=linear_1(output_1).view(10, 256, w//4, h//4)   \n",
    "        # print(res_1.shape,  \"Required 10, 256, 8, 8\")\n",
    "        sb_1=self.sobel_1(res_1)\n",
    "        erb_1=self.erb1(sb_1)\n",
    "\n",
    "\n",
    "        input_resize_2=torch.nn.functional.interpolate(res_1,size=(224,224))      \n",
    "        resnet_2=MyResNet50(256)\n",
    "        output_2=resnet_2(input_resize_2)\n",
    "        output_2=self.flatten(output_2)\n",
    "        linear_2=nn.Linear(2048,h//8*w//8*512)\n",
    "        res_2=linear_2(output_1).view(10, 512, w//8, h//8)     \n",
    "        # print(res_2.shape,  \"Required 10, 512, 4, 4\")\n",
    "        sb_2=self.sobel_2(res_2)\n",
    "        erb_2=self.erb2(sb_2)\n",
    "\n",
    "\n",
    "        input_resize_3=torch.nn.functional.interpolate(res_2,size=(224,224))\n",
    "        resnet_3=MyResNet50(512)\n",
    "        output_3=resnet_3(input_resize_3)\n",
    "        output_3=self.mx(output_3)\n",
    "        output_3=self.flatten(output_3)\n",
    "        linear_3=nn.Linear(2048,h//16*w//16*1024)\n",
    "        res_3=linear_3(output_3).view(10, 1024, w//16, h//16)       \n",
    "        # print(res_3.shape,  \"Required 10, 1024, 2, 2\")\n",
    "        sb_3=self.sobel_3(res_3)\n",
    "        erb_3=self.erb3(sb_3)\n",
    "\n",
    "\n",
    "        input_resize_4=torch.nn.functional.interpolate(res_3,size=(224,224))\n",
    "        resnet_4=MyResNet50(1024)\n",
    "        output_4=resnet_4(input_resize_4)\n",
    "        output_4=self.mx(output_4)\n",
    "        output_4=self.flatten(output_4)\n",
    "        linear_4=nn.Linear(2048,h//16*w//16*2048)\n",
    "        res_4=linear_4(output_4).view(10, 2048, w//16, h//16)          \n",
    "        # print(res_4.shape,  \"Required 10, 2048, 2, 2\")\n",
    "        sb_4=self.sobel_4(res_4)\n",
    "        erb_4=self.erb4(sb_4)\n",
    "\n",
    "\n",
    "        erb_out1=erb_1+self.scale1(erb_2)\n",
    "        erb_out_2=self.erb5(erb_out1)\n",
    "        erb_out_3=self.scale2(erb_3)+erb_out_2\n",
    "        erb_out_4=self.erb5(erb_out_3)\n",
    "        erb_out_5=self.scale2(erb_4)+erb_out_4\n",
    "        final_erb_out=self.erb5(erb_out_5)\n",
    "\n",
    "        edge_out=self.sig(final_erb_out)\n",
    "\n",
    "        bayar_out=self.bayar(x)\n",
    "\n",
    "        input_resize_b1=torch.nn.functional.interpolate(bayar_out,size=(224,224))\n",
    "        output_1=self.conv_layer(input_resize_b1)\n",
    "        output_1=self.mx(output_1)\n",
    "        output_1=self.flatten(output_1)\n",
    "        linear_1=nn.Linear(2048,h//4*w//4*256)\n",
    "        res_11=linear_1(output_1).view(10, 256, w//4, h//4)   \n",
    "      \n",
    "\n",
    "\n",
    "        input_resize_b2=torch.nn.functional.interpolate(res_11,size=(224,224))      \n",
    "        resnet_2=MyResNet50(256)\n",
    "        output_2=resnet_2(input_resize_b2)\n",
    "        output_2=self.flatten(output_2)\n",
    "        linear_2=nn.Linear(2048,h//8*w//8*512)\n",
    "        res_22=linear_2(output_1).view(10, 512, w//8, h//8)     \n",
    "      \n",
    "\n",
    "\n",
    "        input_resize_b3=torch.nn.functional.interpolate(res_22,size=(224,224))\n",
    "        resnet_3=MyResNet50(512)\n",
    "        output_3=resnet_3(input_resize_b3)\n",
    "        output_3=self.mx(output_3)\n",
    "        output_3=self.flatten(output_3)\n",
    "        linear_3=nn.Linear(2048,h//16*w//16*1024)\n",
    "        res_33=linear_3(output_3).view(10, 1024, w//16, h//16)       \n",
    "        \n",
    "\n",
    "\n",
    "        input_resize_b4=torch.nn.functional.interpolate(res_33,size=(224,224))\n",
    "        resnet_4=MyResNet50(1024)\n",
    "        output_4=resnet_4(input_resize_b4)\n",
    "        output_4=self.mx(output_4)\n",
    "        output_4=self.flatten(output_4)\n",
    "        linear_4=nn.Linear(2048,h//16*w//16*2048)\n",
    "        res_44=linear_4(output_4).view(10, 2048, w//16, h//16)          \n",
    "       \n",
    "        dual_concat=torch.cat([res_4,res_44],dim=1)\n",
    "\n",
    "        dual_out=self.dual(dual_concat)\n",
    "\n",
    "        final_dual=self.sig(dual_out)\n",
    "\n",
    "        global_max_val=self.gmp(final_dual)\n",
    "\n",
    "        return edge_out,final_dual,global_max_val\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
